import os            # file path method
import pickle        # sequence and anti-sequence object
import json          # Json document process
import base64        # Base64 encode
import logging       # Log record
import datetime      # Date and time process
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from google.auth.transport.requests import Request
from PersonalAIassistant.app.database.db import Base, engine, SessionLocal
from PersonalAIassistant.app.models_oma.ai_emails_bean import AIEmails
from email.utils import parsedate_to_datetime

# Logging level
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",  # log format
    handlers=[logging.FileHandler("gmail_fetcher.log"), logging.StreamHandler()]  # output to document and console
)


class AIEmailDataProcess:
    """Gmail API email fetcher and processor"""
    # Gmail APIé‚®ä»¶èŽ·å–å™¨å’Œå¤„ç†å™¨

    def __init__(self, credentials_file='credentials.json', token_file='token.pickle'):
        self.SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']   #API permisson scope
        self.credentials_file = credentials_file  # Google API credential file# APIæƒé™èŒƒå›´ï¼ˆåªè¯»ï¼‰
        self.token_file = token_file   # Authentication token cache file # è®¤è¯tokenç¼“å­˜æ–‡ä»¶
        self.service = None   # Gmail Service Users# GmailæœåŠ¡å¯¹è±¡
        self.processed_emails = set() ## Set of Processed Email IDs# å·²å¤„ç†é‚®ä»¶IDé›†åˆ
        self.load_processed_emails() ## Loading processed email records# åŠ è½½å·²å¤„ç†çš„é‚®ä»¶è®°å½•

        print ("Initial AIEamilDataProcess")
        Base.metadata.create_all (bind=engine)
        self.session = SessionLocal ()
        print ("å¯¼å…¥æˆåŠŸï¼Œæ•°æ®åº“è¿žæŽ¥å¯ç”¨")
        #self.session.close ()


    def get_email_service(self):
        """Initialize Gmail API service"""
        creds = None
        # æ£€æŸ¥ token æ–‡ä»¶ # Check if a token file already exists
        if os.path.exists(self.token_file):
            with open(self.token_file, 'rb') as token:
                creds = pickle.load(token) ##åŠ è½½å·²ä¿å­˜çš„å‡­è¯

        # æ²¡æœ‰æœ‰æ•ˆå‡­è¯å°±é‡æ–°æŽˆæƒ
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                # é¦–æ¬¡æŽˆæƒæµç¨‹
                if not os.path.exists(self.credentials_file):
                    raise FileNotFoundError(f"credentials file not found: {self.credentials_file}")
                flow = InstalledAppFlow.from_client_secrets_file(
                    self.credentials_file, self.SCOPES
                )
                creds = flow.run_local_server(port=0) # æœ¬åœ°æœåŠ¡å™¨æ–¹å¼æŽˆæƒ
            # ä¿å­˜æ–°çš„token
            with open(self.token_file, 'wb') as token:
                pickle.dump(creds, token)
        # æž„å»ºGmail APIæœåŠ¡
        self.service = build('gmail', 'v1', credentials=creds)
        return self.service

    def load_processed_emails(self):
        """Load already processed emails from JSON"""
        """ä»ŽJSONæ–‡ä»¶åŠ è½½å·²å¤„ç†çš„é‚®ä»¶ID"""
        self.processed_emails = set()
        try:
            if os.path.exists('processed_emails.json'):
                with open('processed_emails.json', 'r') as f:
                    self.processed_emails = set(json.load(f))
        except Exception as e:
            logging.warning(f"Failed to load processed emails: {e}")

    def save_processed_emails(self):
        """Save processed emails to JSON"""
        """ä¿å­˜å·²å¤„ç†çš„é‚®ä»¶IDåˆ°JSONæ–‡ä»¶"""
        try:
            with open('processed_emails.json', 'w') as f:
                json.dump(list(self.processed_emails), f)
        except Exception as e:
            logging.error(f"Failed to save processed emails: {e}")




    # Using Google API to get all email data
    def get_all_emails(self, days_back=100):
        """Get all emails from last N days"""
        if not self.service:
            self.get_email_service()  # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–

        try:
            # è®¡ç®—æŸ¥è¯¢æ—¥æœŸï¼ˆ30å¤©å‰ï¼‰
            after_date = (datetime.datetime.now() - datetime.timedelta(days=days_back)).strftime('%Y/%m/%d')
            query = f'after:{after_date}'  # Gmailæœç´¢æŸ¥è¯¢è¯­æ³•
            all_messages = []
            page_token = None

            # åˆ†é¡µèŽ·å–æ‰€æœ‰é‚®ä»¶ï¼ˆGmail APIé™åˆ¶æ¯é¡µ500æ¡ï¼‰
            while True:
                response = self.service.users().messages().list(
                    userId='me', # å½“å‰ç”¨æˆ·
                    q=query, # æœç´¢æ¡ä»¶
                    pageToken=page_token,# åˆ†é¡µtoken
                    maxResults=500 # æ¯é¡µæœ€å¤§ç»“æžœæ•°
                ).execute()

                messages = response.get('messages', [])
                all_messages.extend(messages)

                page_token = response.get('nextPageToken')
                if not page_token: # æ²¡æœ‰ä¸‹ä¸€é¡µæ—¶é€€å‡ºå¾ªçŽ¯
                    break

            logging.info(f"âœ… Found {len(all_messages)} emails in the last {days_back} days.")
            return all_messages

        except Exception as e:
            logging.error(f"âŒ Error fetching emails: {e}")
            return []

    def get_message_details(self, message_id):
        """Get full message details"""
        try:
            message = self.service.users().messages().get(
                userId='me',
                id=message_id,
                format='full' # èŽ·å–å®Œæ•´é‚®ä»¶å†…å®¹
            ).execute()
            return message
        except Exception as e:
            logging.error(f"Failed to get message {message_id}: {e}")
            return None

    def parse_message(self, message):
        """Extract email content"""
        try:
            headers = message['payload'].get('headers', [])
            # ä»Žé‚®ä»¶å¤´æå–å…³é”®ä¿¡æ¯
            subject = next((h['value'] for h in headers if h['name'] == 'Subject'), 'No Subject')
            sender = next((h['value'] for h in headers if h['name'] == 'From'), 'Unknown Sender')
            recipient = next((h['value'] for h in headers if h['name'] == 'To'), '')
            date = next((h['value'] for h in headers if h['name'] == 'Date'), 'Unknown Date')
            message_id = next((h['value'] for h in headers if h['name'] == 'Message-ID'), '')

            # æå–é‚®ä»¶æ­£æ–‡
            body = self.extract_body(message['payload'])

            return {
                'id': message['id'],  # Gmailå†…éƒ¨ID
                'message_id': message_id, # é‚®ä»¶Message-ID
                'subject': subject, # é‚®ä»¶ä¸»é¢˜
                'sender': sender, # å‘ä»¶äºº
                'recipient': recipient, #æŽ¥æ”¶äºº
                'date': date, # å‘é€æ—¥æœŸ
                'body': body, # é‚®ä»¶æ­£æ–‡
                'snippet': message.get('snippet', ''), # é‚®ä»¶æ‘˜è¦
                'internalDate': message.get('internalDate', ''), # å†…éƒ¨æ—¶é—´æˆ³
                'labelIds': message.get('labelIds', []) # æ ‡ç­¾IDåˆ—è¡¨
            }
        except Exception as e:
            logging.error(f"Failed to parse message: {e}")
            return None

    def extract_body(self, payload):
        """Extract plain text body from payload"""

        body = ""
        if 'parts' in payload: # å¤šéƒ¨åˆ†é‚®ä»¶ï¼ˆå¸¸è§ï¼‰
            for part in payload['parts']:
                if part.get('mimeType') == 'text/plain' and 'data' in part['body']:
                    # æ‰¾åˆ°çº¯æ–‡æœ¬éƒ¨åˆ†å¹¶è§£ç 
                    data = part['body']['data']
                    body = base64.urlsafe_b64decode(data).decode('utf-8')
                    break
                elif part.get('mimeType') == 'multipart/alternative':
                    # é€’å½’å¤„ç†åµŒå¥—çš„å¤šéƒ¨åˆ†é‚®ä»¶
                    body = self.extract_body(part)
                    if body:
                        break
        else:
            # å•éƒ¨åˆ†é‚®ä»¶
            if payload.get('mimeType') == 'text/plain' and 'data' in payload.get('body', {}):
                data = payload['body']['data']
                body = base64.urlsafe_b64decode(data).decode('utf-8')

        return body

    def run(self, days_back: int):
        """Main execution"""
        self.get_email_service() # åˆå§‹åŒ–æœåŠ¡
        emails = self.get_all_emails(days_back) # èŽ·å–é‚®ä»¶åˆ—è¡¨
        for msg in emails:
            msg_id = msg['id']
            if msg_id in self.processed_emails: # è·³è¿‡å·²å¤„ç†çš„é‚®ä»¶
                continue
            message = self.get_message_details(msg_id)  # èŽ·å–é‚®ä»¶è¯¦æƒ…
            if message:
                parsed = self.parse_message(message)  # è§£æžé‚®ä»¶
                if parsed:
                    date_str = parsed.get ("date" , None)
                    if date_str:
                        try:
                            trigger_time = parsedate_to_datetime (date_str)
                        except Exception:
                            trigger_time = datetime.datetime.utcnow ()
                    else:
                        trigger_time = datetime.datetime.utcnow ()

                    # TODO: save to DB
                    email  = AIEmails(
                        user_id =1,
                        email_title=parsed.get("subject","No Subject"),
                        email_priority_type=parsed.get("priority","Normal"),
                        email_content=parsed.get("body",""),
                        email_from=parsed.get("from",""),
                        email_to = parsed.get("recipient",""),
                        email_time=trigger_time
                    )
                    self.insert_email(email)
                    logging.info(f"Processed email: {parsed['subject']}")
                    self.processed_emails.add(msg_id) # æ ‡è®°ä¸ºå·²å¤„ç†
        self.save_processed_emails() # ä¿å­˜å¤„ç†è®°å½•
        logging.info("ðŸŽ‰ Email data processing completed.")




    # Insert a new data
    def insert_email(self, email: AIEmails):
        existing = self.session.query(AIEmails).filter_by(email_title=email.email_title).first()
        if existing:
            return existing.email_id
        self.session.add(email)
        self.session.commit()
        self.session.refresh(email)
        return email.email_id

    # Select Data by email_title
    def get_user_by_id(self, title: str):
        return self.session.query(AIEmails).filter(AIEmails.email_title == title).first()

    # Select Data by email
    def get_user_by_email(self, email: str):
        return self.session.query(Users).filter(Users.email == email).first()

    # Get user by email_to
    def get_user_by_username(self, email_to: str):
        return self.session.query(AIEmails).filter(AIEmails.email_to == email_to).first()

    # Update data by email_title
    def update_email(self, email_title: str, updates: dict):
        email = self.session.query(AIEmails).filter_by(email_title=email_title).first()
        if not email:
            return None
        for key, value in updates.items():
            setattr(email, key, value)
        self.session.commit()
        self.session.refresh(email)
        return email

    # Get emails greater by email_time
    def get_emails_by_emailtime( self, since_time ):
        return self.session.query(AIEmails).filter(AIEmails.email_time > since_time).all()

if __name__ == '__main__':
    processor = AIEmailDataProcess(
        credentials_file='credentials.json',
        token_file='token.pickle'
    )
    processor.run(days_back=600)
    processor.session.close()
